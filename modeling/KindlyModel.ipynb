{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Emmanuel\n",
      "[nltk_data]     Djaba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Emmanuel\n",
      "[nltk_data]     Djaba\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d62a64e-a26d-48d2-9316-0dd5370a8a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378535e9-5dc2-4109-a495-48876ce4acea",
   "metadata": {},
   "source": [
    "## Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f173865-0d3a-4fbc-a0d6-d70dc5796e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load text and labels\n",
    "train_text = pd.read_csv('dataset/offensive_train_text.txt', delimiter = \"\\t\",header=None,names=[\"Text\"])\n",
    "train_labels = pd.read_csv('dataset/offensive_train_labels.txt', delimiter = \"\\t\",header=None,names=[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbfc2773-7571-4961-9f2d-27eb682597a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine text and labels into one dataset\n",
    "dataset = pd.concat([train_text,train_labels],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488fbffb-2284-4420-8a20-274b9e3cf1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back off</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseball was horrible</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>don't come to school, will kill you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>go kill yourself</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Text  Label\n",
       "0                             back off      1\n",
       "1                baseball was horrible      1\n",
       "2  don't come to school, will kill you      1\n",
       "3                     go kill yourself      1\n",
       "4                                 haha      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed076b3-475b-412b-8fb4-55bc94070109",
   "metadata": {},
   "source": [
    "### Generate tokens out of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce6899c-6325-4be9-b65f-3aa6e001c676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty column to store the tokens\n",
    "dataset[\"Tokens\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c1017e4-7a7a-48d3-b8a1-a9b1272fd86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokens for each line of text\n",
    "for ind in dataset.index:\n",
    "    words = TextBlob(dataset[\"Text\"][ind]).words\n",
    "    # remove punctuation from each word\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    dataset[\"Tokens\"][ind] = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d610a78d-e76d-4157-b1ad-fc2c22f04b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>you silly</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, silly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>you suck so much</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, suck, so, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>you're ugly and fat</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, ugly, and, fat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>you're ugly and stupid</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, ugly, and, stupid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>you make me laugh a lot</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, make, me, laugh, a, lot]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Text  Label                          Tokens\n",
       "120                you silly      1                    [you, silly]\n",
       "121         you suck so much      1           [you, suck, so, much]\n",
       "122      you're ugly and fat      1           [you, ugly, and, fat]\n",
       "123   you're ugly and stupid      1        [you, ugly, and, stupid]\n",
       "124  you make me laugh a lot      0  [you, make, me, laugh, a, lot]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35faf436-f6e5-48f2-b89c-67e571df2b33",
   "metadata": {},
   "source": [
    "### Reduce each word to its root via lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df360309-5e8b-4ad5-9d03-22e998679aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27d7c3d-435c-4b86-a244-14211617db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty column to store the cleaned words\n",
    "dataset[\"Cleaned\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f93065-9312-470a-a4fb-5fff1aa3648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tokens for each line of text\n",
    "for ind in dataset.index:\n",
    "    tokens = dataset[\"Tokens\"][ind]\n",
    "    cleaned_words = []\n",
    "    for token in tokens:\n",
    "        cleaned_words.append(lemmatizer.lemmatize(token))\n",
    "    dataset[\"Cleaned\"][ind] = cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc846a41-b855-4c29-96be-9e99530e0c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>you silly</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, silly]</td>\n",
       "      <td>[you, silly]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>you suck so much</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, suck, so, much]</td>\n",
       "      <td>[you, suck, so, much]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>you're ugly and fat</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, ugly, and, fat]</td>\n",
       "      <td>[you, ugly, and, fat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>you're ugly and stupid</td>\n",
       "      <td>1</td>\n",
       "      <td>[you, ugly, and, stupid]</td>\n",
       "      <td>[you, ugly, and, stupid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>you make me laugh a lot</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, make, me, laugh, a, lot]</td>\n",
       "      <td>[you, make, me, laugh, a, lot]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Text  Label                          Tokens  \\\n",
       "120                you silly      1                    [you, silly]   \n",
       "121         you suck so much      1           [you, suck, so, much]   \n",
       "122      you're ugly and fat      1           [you, ugly, and, fat]   \n",
       "123   you're ugly and stupid      1        [you, ugly, and, stupid]   \n",
       "124  you make me laugh a lot      0  [you, make, me, laugh, a, lot]   \n",
       "\n",
       "                            Cleaned  \n",
       "120                    [you, silly]  \n",
       "121           [you, suck, so, much]  \n",
       "122           [you, ugly, and, fat]  \n",
       "123        [you, ugly, and, stupid]  \n",
       "124  [you, make, me, laugh, a, lot]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a6bdd-a2f6-4aad-ac84-cc4bf308b418",
   "metadata": {},
   "source": [
    "### Generate vector for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "010f4ae4-5041-417c-a22e-153e0ee8bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sentences from stemmed tokens \n",
    "np_docs = []\n",
    "for ind in dataset.index:\n",
    "    res = ' '.join(dataset['Cleaned'][ind])\n",
    "    np_docs.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e8d9aa-73db-499a-b8b7-0ddc3988b64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit tfidf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10)\n",
    "doc_vec = vectorizer.fit(np_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eac5bc16-3d65-4a09-bb88-f729f2722897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty column to store TFIDF\n",
    "dataset[\"TFIDF\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c920bedb-bfa0-41dc-9099-803034d65d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in dataset.index:\n",
    "    dataset[\"TFIDF\"][ind] = vectorizer.transform(dataset[\"Cleaned\"][ind]).toarray()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8497bf3d-d526-4a09-92bc-5983319e1d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back off</td>\n",
       "      <td>1</td>\n",
       "      <td>[back, off]</td>\n",
       "      <td>[back, off]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>baseball was horrible</td>\n",
       "      <td>1</td>\n",
       "      <td>[baseball, was, horrible]</td>\n",
       "      <td>[baseball, wa, horrible]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Text  Label                     Tokens  \\\n",
       "0               back off      1                [back, off]   \n",
       "1  baseball was horrible      1  [baseball, was, horrible]   \n",
       "\n",
       "                    Cleaned  \\\n",
       "0               [back, off]   \n",
       "1  [baseball, wa, horrible]   \n",
       "\n",
       "                                                TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eaa5fc-88ca-4792-b010-8f69c1a68c2f",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17bc2541-7aa1-4dac-8859-3883313088cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c775379b-93e0-4819-9822-0a6342ab9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather features\n",
    "features = []\n",
    "for ind in dataset.index:\n",
    "    features.append(dataset['TFIDF'][ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "508df095-5f44-4fa5-a539-fee18db450de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#because we have only one feature   \n",
    "for f in features:\n",
    "    f = f.reshape(-1,1)\n",
    "\n",
    "features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d16d6e7-8149-4143-83aa-e6a4c7d10890",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for ind in dataset.index:\n",
    "    labels.append(dataset['Label'][ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a34b0af-51cf-4986-b126-0e163f23141b",
   "metadata": {},
   "source": [
    "### Visualize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a503b46e-4abf-4893-baa2-ccd53115c13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70fd65ec-85fc-4a91-a368-b23ec8bdfe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=2).fit(features)\n",
    "data2D = pca.transform(features)\n",
    "x_coordinates = data2D[:,0]\n",
    "y_coordinates =  data2D[:,1]\n",
    "                \n",
    "for x, y in zip(x_coordinates, y_coordinates):\n",
    "    rgb = np.random.rand(3,)\n",
    "    plt.scatter(x, y, c=[rgb])\n",
    "plt.show()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f6354e4-c86f-474f-b619-b96bee26acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test splits\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(features,labels,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20872177-0a46-42d0-b47c-973ae817d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare  input\n",
    "def prepare_input(sample_text):\n",
    "    words = TextBlob(sample_text).words\n",
    "    # remove punctuation from each word\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        cleaned_words.append(lemmatizer.lemmatize(word))\n",
    "    return vectorizer.transform(cleaned_words).toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c70d9e-554c-47f3-bf89-c61b20e4fa10",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9e655fa-2f6d-4a90-9e59-5f93fcd78056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh_model = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh_model.fit(Train_X, Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d35ae37-f59c-488d-918b-bf16217d06c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors Accuracy Score ->  100.0\n"
     ]
    }
   ],
   "source": [
    "predictions_neigh = neigh_model.predict(Test_X)\n",
    "print(\"Nearest Neighbors Accuracy Score -> \",accuracy_score(predictions_neigh, Test_Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f828ca0e-8b66-4049-89e6-d0e5f9d24072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert test text here\n",
    "test_text = \"I have so much homework im going to die\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "567098a1-14b9-4d03-8a9c-982e80807717",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = prepare_input(test_text).reshape(1, -1)\n",
    "predicted_value = neigh_model.predict(test_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d46cf54-1667-40c1-a536-36651a274f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920344ed-a0a5-40f0-a89b-3c9627010888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
